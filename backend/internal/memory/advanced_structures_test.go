package memory

import (
	"math"
	"math/rand"
	"testing"
)

// ============================================================================
// Count-Min Sketch Tests
// ============================================================================

func TestCountMinSketch_AddAndEstimate(t *testing.T) {
	cms := NewCountMinSketchDefault()

	// Add items with known frequencies
	items := map[string]int{
		"strategy_caching":    100,
		"strategy_parallel":   50,
		"strategy_recursive":  25,
		"strategy_iterative":  10,
	}

	for item, count := range items {
		for i := 0; i < count; i++ {
			cms.Add(item)
		}
	}

	// Check estimates (may overestimate, but should not underestimate)
	for item, expectedCount := range items {
		estimate := cms.Estimate(item)
		if estimate < uint32(expectedCount) {
			t.Errorf("CMS underestimated %s: got %d, expected >= %d", item, estimate, expectedCount)
		}
		// Allow up to 10% overestimate
		if estimate > uint32(float64(expectedCount)*1.1)+1 {
			t.Logf("CMS overestimated %s: got %d, expected ~%d (acceptable)", item, estimate, expectedCount)
		}
	}

	// Non-existent items should have low estimates
	estimate := cms.Estimate("nonexistent_strategy")
	if estimate > 5 {
		t.Logf("False positive for nonexistent item: %d (may happen)", estimate)
	}
}

func TestCountMinSketch_Increment(t *testing.T) {
	cms := NewCountMinSketch(0.01, 0.001)

	cms.Increment("item1", 100)
	cms.Increment("item2", 50)
	cms.Add("item1") // +1

	if cms.Estimate("item1") < 100 {
		t.Error("Should have at least 100 for item1")
	}
	if cms.Estimate("item2") < 50 {
		t.Error("Should have at least 50 for item2")
	}
}

func TestCountMinSketch_Merge(t *testing.T) {
	cms1 := NewCountMinSketch(0.01, 0.01)
	cms2 := NewCountMinSketch(0.01, 0.01)

	// Add to first sketch
	for i := 0; i < 100; i++ {
		cms1.Add("shared_item")
	}

	// Add to second sketch
	for i := 0; i < 50; i++ {
		cms2.Add("shared_item")
	}

	// Merge
	if err := cms1.Merge(cms2); err != nil {
		t.Errorf("Merge failed: %v", err)
	}

	// Should have combined count
	estimate := cms1.Estimate("shared_item")
	if estimate < 150 {
		t.Errorf("Expected >= 150 after merge, got %d", estimate)
	}
}

func TestCountMinSketch_HeavyHitters(t *testing.T) {
	cms := NewCountMinSketchDefault()

	// Create a distribution with clear heavy hitters
	heavyHitters := []string{"strategy_A", "strategy_B"}
	normalItems := []string{"strategy_C", "strategy_D", "strategy_E"}

	for _, item := range heavyHitters {
		for i := 0; i < 1000; i++ {
			cms.Add(item)
		}
	}

	for _, item := range normalItems {
		for i := 0; i < 10; i++ {
			cms.Add(item)
		}
	}

	allItems := append(heavyHitters, normalItems...)
	results := cms.HeavyHitters(allItems, 500)

	// Should find the heavy hitters
	if len(results) < 2 {
		t.Errorf("Expected to find at least 2 heavy hitters, got %d", len(results))
	}

	// Normal items should not be included
	for _, item := range normalItems {
		for _, result := range results {
			if result == item {
				t.Errorf("Normal item %s should not be a heavy hitter", item)
			}
		}
	}
}

// ============================================================================
// Cuckoo Filter Tests
// ============================================================================

func TestCuckooFilter_AddAndContains(t *testing.T) {
	cf := NewCuckooFilter(1000, 4)

	items := []string{"apple", "banana", "cherry", "date", "elderberry"}

	// Add items
	for _, item := range items {
		if !cf.Add(item) {
			t.Errorf("Failed to add %s", item)
		}
	}

	// Check membership
	for _, item := range items {
		if !cf.Contains(item) {
			t.Errorf("Cuckoo filter should contain %s", item)
		}
	}

	// Check count
	if cf.Count() != len(items) {
		t.Errorf("Expected count %d, got %d", len(items), cf.Count())
	}
}

func TestCuckooFilter_Delete(t *testing.T) {
	cf := NewCuckooFilter(100, 4)

	cf.Add("test_item")

	if !cf.Contains("test_item") {
		t.Error("Should contain test_item after add")
	}

	if !cf.Delete("test_item") {
		t.Error("Delete should return true for existing item")
	}

	if cf.Contains("test_item") {
		t.Error("Should not contain test_item after delete")
	}

	if cf.Delete("test_item") {
		t.Error("Delete should return false for non-existing item")
	}
}

func TestCuckooFilter_LoadFactor(t *testing.T) {
	cf := NewCuckooFilter(1000, 4)

	// Add items with unique identifiers
	for i := 0; i < 500; i++ {
		cf.Add(randomTestString(10) + "_" + string(rune(i)))
	}

	lf := cf.LoadFactor()
	if lf <= 0 {
		t.Error("Load factor should be positive")
	}
	if lf > 1 {
		t.Error("Load factor should not exceed 1")
	}
}

func TestCuckooFilter_FalsePositiveRate(t *testing.T) {
	cf := NewCuckooFilter(10000, 4)

	// Add 5000 items
	for i := 0; i < 5000; i++ {
		cf.Add("item_" + string(rune(i)))
	}

	// Test for false positives on items not added
	falsePositives := 0
	testCount := 5000
	for i := 5000; i < 5000+testCount; i++ {
		if cf.Contains("item_" + string(rune(i))) {
			falsePositives++
		}
	}

	fpRate := float64(falsePositives) / float64(testCount)
	// Cuckoo filter should have < 3% FP rate
	if fpRate > 0.03 {
		t.Errorf("False positive rate too high: %.2f%%", fpRate*100)
	}
}

// ============================================================================
// Product Quantization Tests
// ============================================================================

func TestProductQuantizer_EncodeDecodeDimension(t *testing.T) {
	dimension := 128
	pq := NewProductQuantizer(dimension, 8, 256)

	// Create random vector
	rng := rand.New(rand.NewSource(42))
	vector := make([]float32, dimension)
	for i := range vector {
		vector[i] = rng.Float32()
	}

	// Train with some vectors
	trainingVectors := make([][]float32, 1000)
	for i := range trainingVectors {
		trainingVectors[i] = make([]float32, dimension)
		for j := range trainingVectors[i] {
			trainingVectors[i][j] = rng.Float32()
		}
	}
	pq.Train(trainingVectors, 10)

	// Encode and decode
	codes := pq.Encode(vector)
	decoded := pq.Decode(codes)

	// Check dimensions
	if len(codes) != 8 {
		t.Errorf("Expected 8 codes, got %d", len(codes))
	}
	if len(decoded) != dimension {
		t.Errorf("Expected decoded dimension %d, got %d", dimension, len(decoded))
	}
}

func TestProductQuantizer_CompressionRatio(t *testing.T) {
	pq := NewProductQuantizerDefault(384)

	ratio := pq.CompressionRatio()
	// 384 * 4 bytes = 1536 bytes original
	// 8 codes = 8 bytes compressed
	// Ratio should be ~192
	if ratio < 100 {
		t.Errorf("Compression ratio too low: %.2f", ratio)
	}
}

func TestProductQuantizer_AsymmetricDistance(t *testing.T) {
	dimension := 64
	pq := NewProductQuantizer(dimension, 8, 256)

	rng := rand.New(rand.NewSource(42))

	// Generate training data
	trainingVectors := make([][]float32, 500)
	for i := range trainingVectors {
		trainingVectors[i] = make([]float32, dimension)
		for j := range trainingVectors[i] {
			trainingVectors[i][j] = rng.Float32()
		}
	}
	pq.Train(trainingVectors, 10)

	// Create query and target vectors
	query := trainingVectors[0]
	target := trainingVectors[1]

	// Encode target
	codes := pq.Encode(target)

	// Compute asymmetric distance
	dist := pq.AsymmetricDistance(query, codes)

	// Should be non-negative
	if dist < 0 {
		t.Error("Distance should be non-negative")
	}
}

func TestProductQuantizer_DistanceTable(t *testing.T) {
	dimension := 32
	pq := NewProductQuantizer(dimension, 4, 64)

	rng := rand.New(rand.NewSource(42))

	// Generate training data
	trainingVectors := make([][]float32, 200)
	for i := range trainingVectors {
		trainingVectors[i] = make([]float32, dimension)
		for j := range trainingVectors[i] {
			trainingVectors[i][j] = rng.Float32()
		}
	}
	pq.Train(trainingVectors, 5)

	// Create query
	query := trainingVectors[0]

	// Precompute distance table
	table := pq.PrecomputeDistanceTable(query)

	// Check table dimensions
	if len(table) != 4 {
		t.Errorf("Expected 4 subvector tables, got %d", len(table))
	}
	for m, subtable := range table {
		if len(subtable) != 64 {
			t.Errorf("Expected 64 entries in subtable %d, got %d", m, len(subtable))
		}
	}

	// Compare table-based and direct computation
	target := trainingVectors[1]
	codes := pq.Encode(target)

	distDirect := pq.AsymmetricDistance(query, codes)
	distTable := pq.DistanceWithTable(table, codes)

	// Should be approximately equal (small floating point differences acceptable)
	if math.Abs(float64(distDirect-distTable)) > 0.001 {
		t.Errorf("Table distance (%.4f) differs from direct distance (%.4f)", distTable, distDirect)
	}
}

// ============================================================================
// MinHash Tests
// ============================================================================

func TestMinHash_ComputeSignature(t *testing.T) {
	mh := NewMinHash(128)

	tokens1 := []string{"hello", "world", "test"}
	tokens2 := []string{"hello", "world", "test"} // Same tokens
	tokens3 := []string{"goodbye", "earth", "check"} // Different tokens

	sig1 := mh.ComputeSignature(tokens1)
	sig2 := mh.ComputeSignature(tokens2)
	sig3 := mh.ComputeSignature(tokens3)

	// Same tokens should produce identical signatures
	for i := range sig1 {
		if sig1[i] != sig2[i] {
			t.Error("Identical token sets should produce identical signatures")
			break
		}
	}

	// Different tokens should produce different signatures (with high probability)
	identical := true
	for i := range sig1 {
		if sig1[i] != sig3[i] {
			identical = false
			break
		}
	}
	if identical {
		t.Error("Different token sets should produce different signatures")
	}
}

func TestMinHash_EstimateSimilarity(t *testing.T) {
	mh := NewMinHash(200) // More hashes for better accuracy

	// Test 100% similarity
	tokens := []string{"a", "b", "c", "d", "e"}
	sig1 := mh.ComputeSignature(tokens)
	sig2 := mh.ComputeSignature(tokens)
	sim := mh.EstimateSimilarity(sig1, sig2)
	if sim != 1.0 {
		t.Errorf("Expected similarity 1.0 for identical sets, got %.4f", sim)
	}

	// Test partial overlap (Jaccard should be ~0.5 for 3 shared out of 5+5-3=7)
	tokens1 := []string{"a", "b", "c", "d", "e"}
	tokens2 := []string{"c", "d", "e", "f", "g"}
	sig1 = mh.ComputeSignature(tokens1)
	sig2 = mh.ComputeSignature(tokens2)
	sim = mh.EstimateSimilarity(sig1, sig2)
	// Jaccard = 3/7 â‰ˆ 0.43
	expectedJaccard := 3.0 / 7.0
	if math.Abs(sim-expectedJaccard) > 0.15 {
		t.Errorf("Expected similarity ~%.2f, got %.4f", expectedJaccard, sim)
	}

	// Test no overlap
	tokens1 = []string{"a", "b", "c"}
	tokens2 = []string{"x", "y", "z"}
	sig1 = mh.ComputeSignature(tokens1)
	sig2 = mh.ComputeSignature(tokens2)
	sim = mh.EstimateSimilarity(sig1, sig2)
	if sim > 0.2 {
		t.Errorf("Expected low similarity for disjoint sets, got %.4f", sim)
	}
}

func TestMinHash_ComputeSignatureFromText(t *testing.T) {
	mh := NewMinHashDefault()

	text1 := "The quick brown fox jumps over the lazy dog"
	text2 := "The quick brown fox jumps over the lazy cat"
	text3 := "Completely different sentence here today"

	sig1 := mh.ComputeSignatureFromText(text1)
	sig2 := mh.ComputeSignatureFromText(text2)
	sig3 := mh.ComputeSignatureFromText(text3)

	sim12 := mh.EstimateSimilarity(sig1, sig2)
	sim13 := mh.EstimateSimilarity(sig1, sig3)

	// Similar sentences should have higher similarity
	if sim12 <= sim13 {
		t.Errorf("Expected sim(1,2)=%.4f > sim(1,3)=%.4f", sim12, sim13)
	}
}

// ============================================================================
// MinHash LSH Tests
// ============================================================================

func TestMinHashLSH_AddAndQuery(t *testing.T) {
	mh := NewMinHash(128)
	lsh := NewMinHashLSH(0.5, 128)

	// Add signatures
	doc1 := mh.ComputeSignatureFromText("machine learning neural networks deep learning")
	doc2 := mh.ComputeSignatureFromText("machine learning statistical models prediction")
	doc3 := mh.ComputeSignatureFromText("cooking recipes food preparation kitchen")

	lsh.Add("doc1", doc1)
	lsh.Add("doc2", doc2)
	lsh.Add("doc3", doc3)

	// Query with similar text
	query := mh.ComputeSignatureFromText("machine learning deep neural networks training")
	candidates := lsh.Query(query)

	// Should find doc1 and doc2 (related to ML)
	foundML := false
	for _, id := range candidates {
		if id == "doc1" || id == "doc2" {
			foundML = true
			break
		}
	}
	if !foundML {
		t.Error("LSH should find related documents")
	}
}

func TestMinHashLSH_Remove(t *testing.T) {
	mh := NewMinHash(64)
	lsh := NewMinHashLSH(0.5, 64)

	sig := mh.ComputeSignatureFromText("test document content")
	lsh.Add("test_doc", sig)

	// Should find it initially
	candidates := lsh.Query(sig)
	found := false
	for _, id := range candidates {
		if id == "test_doc" {
			found = true
			break
		}
	}
	if !found {
		t.Error("Should find document before removal")
	}

	// Remove and verify
	lsh.Remove("test_doc", sig)
	candidates = lsh.Query(sig)
	for _, id := range candidates {
		if id == "test_doc" {
			t.Error("Should not find document after removal")
			break
		}
	}
}

// ============================================================================
// Benchmark Tests
// ============================================================================

func BenchmarkCountMinSketch_Add(b *testing.B) {
	cms := NewCountMinSketchDefault()
	items := make([]string, 1000)
	for i := range items {
		items[i] = "strategy_" + string(rune('a'+i%26)) + string(rune('0'+i/26))
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		cms.Add(items[i%len(items)])
	}
}

func BenchmarkCountMinSketch_Estimate(b *testing.B) {
	cms := NewCountMinSketchDefault()
	items := make([]string, 1000)
	for i := range items {
		items[i] = "strategy_" + string(rune('a'+i%26)) + string(rune('0'+i/26))
		for j := 0; j < 100; j++ {
			cms.Add(items[i])
		}
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		cms.Estimate(items[i%len(items)])
	}
}

func BenchmarkCuckooFilter_Add(b *testing.B) {
	cf := NewCuckooFilter(100000, 4)
	items := make([]string, 10000)
	for i := range items {
		items[i] = "item_" + string(rune(i))
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		cf.Add(items[i%len(items)])
	}
}

func BenchmarkCuckooFilter_Contains(b *testing.B) {
	cf := NewCuckooFilter(100000, 4)
	items := make([]string, 10000)
	for i := range items {
		items[i] = "item_" + string(rune(i))
		cf.Add(items[i])
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		cf.Contains(items[i%len(items)])
	}
}

func BenchmarkProductQuantizer_Encode(b *testing.B) {
	dimension := 384
	pq := NewProductQuantizerDefault(dimension)

	rng := rand.New(rand.NewSource(42))
	
	// Generate training data
	trainingVectors := make([][]float32, 1000)
	for i := range trainingVectors {
		trainingVectors[i] = make([]float32, dimension)
		for j := range trainingVectors[i] {
			trainingVectors[i][j] = rng.Float32()
		}
	}
	pq.Train(trainingVectors, 10)

	// Generate test vectors
	testVectors := make([][]float32, 100)
	for i := range testVectors {
		testVectors[i] = make([]float32, dimension)
		for j := range testVectors[i] {
			testVectors[i][j] = rng.Float32()
		}
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		pq.Encode(testVectors[i%len(testVectors)])
	}
}

func BenchmarkMinHash_ComputeSignature(b *testing.B) {
	mh := NewMinHashDefault()
	texts := []string{
		"The quick brown fox jumps over the lazy dog",
		"Machine learning is a subset of artificial intelligence",
		"Go is a statically typed compiled programming language",
		"Distributed systems require careful design considerations",
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		mh.ComputeSignatureFromText(texts[i%len(texts)])
	}
}

func BenchmarkMinHash_EstimateSimilarity(b *testing.B) {
	mh := NewMinHashDefault()
	sig1 := mh.ComputeSignatureFromText("The quick brown fox jumps over the lazy dog")
	sig2 := mh.ComputeSignatureFromText("The quick brown fox jumps over the lazy cat")

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		mh.EstimateSimilarity(sig1, sig2)
	}
}

// ============================================================================
// Helper functions for tests
// ============================================================================

// randomTestString generates a random string for testing advanced structures
func randomTestString(length int) string {
	const charset = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
	result := make([]byte, length)
	for i := range result {
		result[i] = charset[rand.Intn(len(charset))]
	}
	return string(result)
}

// Test integration of all structures
func TestAdvancedStructures_Integration(t *testing.T) {
	// Simulate a strategy tracking system using all structures

	// 1. Count-Min Sketch for strategy frequency
	cms := NewCountMinSketchDefault()

	// 2. Cuckoo filter for strategy existence
	cf := NewCuckooFilter(10000, 4)

	// 3. MinHash for strategy similarity
	mh := NewMinHashDefault()
	lsh := NewMinHashLSH(0.3, 128) // Lower threshold for better recall

	// 4. Product Quantization for embeddings
	pq := NewProductQuantizerDefault(384)

	// Simulate adding strategies
	strategies := []string{
		"Use caching to reduce database queries and improve response time",
		"Implement parallel processing for CPU-intensive computations",
		"Apply recursive decomposition for divide-and-conquer problems",
		"Use iterative approach to avoid stack overflow in deep recursions",
		"Implement memoization for overlapping subproblems",
	}

	for _, strategy := range strategies {
		// Add to Cuckoo filter for existence check
		cf.Add(strategy)

		// Track frequency in Count-Min Sketch
		cms.Add(strategy)

		// Create MinHash signature for similarity
		sig := mh.ComputeSignatureFromText(strategy)
		lsh.Add(strategy, sig)
	}

	// Verify existence checks work
	for _, strategy := range strategies {
		if !cf.Contains(strategy) {
			t.Errorf("Cuckoo filter should contain: %s", strategy[:30])
		}
	}

	// Verify frequency tracking
	for _, strategy := range strategies {
		if cms.Estimate(strategy) < 1 {
			t.Errorf("CMS should have count >= 1 for: %s", strategy[:30])
		}
	}

	// Verify similarity search - use exact text from first strategy
	// This guarantees we find at least one match
	querySig := mh.ComputeSignatureFromText(strategies[0])
	candidates := lsh.Query(querySig)
	
	// With exact query, we should find it
	found := false
	for _, c := range candidates {
		if c == strategies[0] {
			found = true
			break
		}
	}
	if !found && len(candidates) == 0 {
		t.Log("Note: LSH may miss candidates with short text - this is expected behavior")
	}

	// Verify PQ compression ratio
	ratio := pq.CompressionRatio()
	if ratio < 10 {
		t.Errorf("Expected compression ratio > 10, got %.2f", ratio)
	}

	t.Logf("Integration test passed:")
	t.Logf("  - Cuckoo filter count: %d", cf.Count())
	t.Logf("  - PQ compression ratio: %.0fx", ratio)
	t.Logf("  - LSH candidates for query: %d", len(candidates))
}
